{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network with TF-Slim\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../images/tensorflow.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append(\"../\") \n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model with TF-Slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                    activation_fn=tf.nn.relu,\n",
    "                    weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "                    weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                    biases_initializer=tf.zeros_initializer):\n",
    "    \n",
    "    # default parameters for conv2d\n",
    "    with slim.arg_scope([slim.conv2d], kernel_size = [3,3], padding='SAME'):\n",
    "        \n",
    "        # default parameters for max_pool2d    \n",
    "        with slim.arg_scope([slim.max_pool2d], kernel_size = [2,2], padding = 'SAME'):\n",
    "        \n",
    "            # block 1\n",
    "            net = slim.repeat(inputs, 1, slim.conv2d, 64, scope='conv1')\n",
    "            net = slim.max_pool2d(net, scope='pool1')\n",
    "\n",
    "            # block 2\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, scope='conv2')\n",
    "            net = slim.max_pool2d(net, scope='pool2')\n",
    "\n",
    "            # block 3\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256,, scope='conv3')\n",
    "            net = slim.max_pool2d(net, scope='pool3')\n",
    "\n",
    "            # fc1 (use conv2d instead of fully_connected layers)\n",
    "            net = slim.conv2d(net, 1024, [8, 8], padding='VALID', scope='fc4')\n",
    "            net = slim.dropout(net, dropout, is_training=is_training, scope='dropout4')\n",
    "\n",
    "            # fc2\n",
    "            net = slim.conv2d(net, 1024, [1, 1], scope='fc5')\n",
    "            net = slim.dropout(net, dropout, is_training=is_training, scope='dropout5')\n",
    "\n",
    "            # fc3\n",
    "            net = slim.conv2d(net, output_dim, [1, 1],\n",
    "                              activation_fn=None,\n",
    "                              normalizer_fn=None,\n",
    "                              scope='prediction')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers\n",
      "name = CNN_flowers_classifier/conv1/conv1_1/Relu:0             shape = (?, 64, 64, 64)\n",
      "name = CNN_flowers_classifier/pool1/MaxPool:0                  shape = (?, 32, 32, 64)\n",
      "name = CNN_flowers_classifier/conv2/conv2_1/Relu:0             shape = (?, 32, 32, 128)\n",
      "name = CNN_flowers_classifier/conv2/conv2_2/Relu:0             shape = (?, 32, 32, 128)\n",
      "name = CNN_flowers_classifier/pool2/MaxPool:0                  shape = (?, 16, 16, 128)\n",
      "name = CNN_flowers_classifier/conv3/conv3_1/Relu:0             shape = (?, 16, 16, 256)\n",
      "name = CNN_flowers_classifier/conv3/conv3_2/Relu:0             shape = (?, 16, 16, 256)\n",
      "name = CNN_flowers_classifier/conv3/conv3_3/Relu:0             shape = (?, 16, 16, 256)\n",
      "name = CNN_flowers_classifier/pool3/MaxPool:0                  shape = (?, 8, 8, 256)\n",
      "name = CNN_flowers_classifier/fc4/Relu:0                       shape = (?, 1, 1, 1024)\n",
      "name = CNN_flowers_classifier/fc5/Relu:0                       shape = (?, 1, 1, 1024)\n",
      "name = CNN_flowers_classifier/prediction/squeezed:0            shape = (?, 5)\n",
      "\n",
      "\n",
      "Parameters\n",
      "name = CNN_flowers_classifier/conv1/conv1_1/weights:0          shape = (3, 3, 3, 64)\n",
      "name = CNN_flowers_classifier/conv1/conv1_1/biases:0           shape = (64,)\n",
      "name = CNN_flowers_classifier/conv2/conv2_1/weights:0          shape = (3, 3, 64, 128)\n",
      "name = CNN_flowers_classifier/conv2/conv2_1/biases:0           shape = (128,)\n",
      "name = CNN_flowers_classifier/conv2/conv2_2/weights:0          shape = (3, 3, 128, 128)\n",
      "name = CNN_flowers_classifier/conv2/conv2_2/biases:0           shape = (128,)\n",
      "name = CNN_flowers_classifier/conv3/conv3_1/weights:0          shape = (3, 3, 128, 256)\n",
      "name = CNN_flowers_classifier/conv3/conv3_1/biases:0           shape = (256,)\n",
      "name = CNN_flowers_classifier/conv3/conv3_2/weights:0          shape = (3, 3, 256, 256)\n",
      "name = CNN_flowers_classifier/conv3/conv3_2/biases:0           shape = (256,)\n",
      "name = CNN_flowers_classifier/conv3/conv3_3/weights:0          shape = (3, 3, 256, 256)\n",
      "name = CNN_flowers_classifier/conv3/conv3_3/biases:0           shape = (256,)\n",
      "name = CNN_flowers_classifier/fc4/weights:0                    shape = (8, 8, 256, 1024)\n",
      "name = CNN_flowers_classifier/fc4/biases:0                     shape = (1024,)\n",
      "name = CNN_flowers_classifier/fc5/weights:0                    shape = (1, 1, 1024, 1024)\n",
      "name = CNN_flowers_classifier/fc5/biases:0                     shape = (1024,)\n",
      "name = CNN_flowers_classifier/prediction/weights:0             shape = (1, 1, 1024, 5)\n",
      "name = CNN_flowers_classifier/prediction/biases:0              shape = (5,)\n"
     ]
    }
   ],
   "source": [
    "from utils.slim_models import CNNClassifier\n",
    "\n",
    "image_crop_shape = (64,64,3)\n",
    "num_class = 5\n",
    "\n",
    "CNN_model = CNNClassifier(\"flowers\", image_crop_shape , num_class)\n",
    "CNN_model.examine_model_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Images with DatasetProvider\n",
    "DatasetProvider is located in the *slim_data_provider.py* file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def preprocess_image(image, output_height, output_width):\n",
    "    \"\"\"Preprocesses the given image.\n",
    "    Args:\n",
    "    image: A `Tensor` representing an image of arbitrary size.\n",
    "    output_height: The height of the image after preprocessing.\n",
    "    output_width: The width of the image after preprocessing.\n",
    "\n",
    "    Returns:\n",
    "    A preprocessed image.\n",
    "    \"\"\"\n",
    "    tf.image_summary('image', tf.expand_dims(image, 0))\n",
    "    # Transform the image to floats.\n",
    "    image = tf.to_float(image)\n",
    "\n",
    "    # Resize and crop if needed.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(\n",
    "                    image, output_height, output_width)\n",
    "    tf.image_summary('resized_image', tf.expand_dims(resized_image, 0))\n",
    "\n",
    "    # Linearly scales `image` to have zero mean and unit norm.\n",
    "    return tf.image.image.per_image_standardization(resized_image)\n",
    "\n",
    "def load_batch_flowers(data_type, output_height, output_width, batch_size):\n",
    "    dataset = flowers.get_split(data_type, data_dir)\n",
    "    return load_batch_CNN(output_height, output_width, batch_size)\n",
    "\n",
    "def load_batch_CNN(dataset, data_type, output_height, output_width, batch_size=32):\n",
    "    \"\"\"Loads a single batch of data.\n",
    "\n",
    "    Args:\n",
    "      dataset: The dataset to load.\n",
    "      output_height: The height of the image after preprocessing.\n",
    "      output_width: The width of the image after preprocessing.\n",
    "      batch_size: The number of images in the batch.\n",
    "\n",
    "    Returns:\n",
    "      images: A Tensor of size [batch_size, height, width, 3],\n",
    "              image samples that have been preprocessed.\n",
    "      labels: A Tensor of size [batch_size],whose values range between 0 and num_classes\n",
    "    \"\"\"\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset, common_queue_capacity=32, common_queue_min=8)\n",
    "    image, label = data_provider.get(['image', 'label'])\n",
    "\n",
    "    image = preprocess_image(image, output_height, output_width)\n",
    "\n",
    "    # Batch it up.\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=1,  # one queue\n",
    "        capacity=2 * batch_size)  # two batch per queue max\n",
    "\n",
    "    return images, labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### Deep Convolutional Neural Network for text classification in TensorFlow-Slim\n",
    "-  Define Deep Convolutional Neural Network for classification task on text dataset.\n",
    "\n",
    "<img src=\"../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-latest]",
   "language": "python",
   "name": "conda-env-TF-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

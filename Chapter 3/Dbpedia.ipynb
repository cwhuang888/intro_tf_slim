{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Explore DBpedia Dataset\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../images/tensorflow.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBpedia Ontology Classification Dataset\n",
    "\n",
    "**Description**\n",
    "\n",
    "The DBpedia ontology classification dataset is constructed by picking 14 non-overlapping classes from [DBpedia 2014](http://wiki.dbpedia.org/).\n",
    "\n",
    "They are listed in classes.txt. \n",
    "The dataset is composed of 14 ontology classes, each with 40,000 training samples and 5,000 testing samples.\n",
    "\n",
    "**Total dataset size**\n",
    "- 560,000 training set\n",
    "- 70,000 testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 14 Target classes**\n",
    "1. Company\n",
    "2. EducationalInstitution\n",
    "3. Artist\n",
    "4. Athlete\n",
    "5. OfficeHolder\n",
    "6. MeanOfTransportation\n",
    "7. Building\n",
    "8. NaturalPlace\n",
    "9. Village\n",
    "10. Animal\n",
    "11. Plant\n",
    "12. Album\n",
    "13. Film\n",
    "14. WrittenWork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tensorflow Slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append(\"../\") \n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Text Dataset Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.datasets import text_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Load DBpedia Dataset\n",
    "In `text_datasets.load_dbpedia()`, you can set the `size` parameter:\n",
    "\n",
    "`small` only loads 0.1% of the total dataset (ie 560 train and 70 test observations)\n",
    "`normal` loads total dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = text_datasets.load_dbpedia(size='small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_target_classes(class_file_path):\n",
    "    with open(class_file_path) as f:  \n",
    "        return map(lambda x: x.strip(), f.readlines())\n",
    "\n",
    "def explore_dbpedia_data(data, classes, sample_size = 5):\n",
    "    idx = np.random.choice(len(data.train.data), sample_size, replace=False)\n",
    "    target_sample = data.train.target[idx]\n",
    "    train_data_sample = data.train.data[idx]\n",
    "    \n",
    "    for target, sample in zip(target_sample, train_data_sample):\n",
    "        print(\"Title: {}\".format(sample[0]))\n",
    "        print(\"Target Class: {}\".format(classes[target-1]))\n",
    "        print(\"Content:\\n {}\\n\".format(sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Company',\n",
       " 'EducationalInstitution',\n",
       " 'Artist',\n",
       " 'Athlete',\n",
       " 'OfficeHolder',\n",
       " 'MeanOfTransportation',\n",
       " 'Building',\n",
       " 'NaturalPlace',\n",
       " 'Village',\n",
       " 'Animal',\n",
       " 'Plant',\n",
       " 'Album',\n",
       " 'Film',\n",
       " 'WrittenWork']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_file_path = \"dbpedia_data/dbpedia_csv/classes.txt\"\n",
    "\n",
    "classes = load_target_classes(class_file_path)\n",
    "print(\"Number of classes: {}\".format(len(classes)))\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore DBpedia Data\n",
    "Pick sample size and the function below will return a random sample with actual text content, title and target class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sadako 3D 2\n",
      "Target Class: Film\n",
      "Content:\n",
      "  Sadako 3D 2 (貞子3D2) is a 2013 Japanese horror film directed by Tsutomu Hanabusa and the second installment of the Sadako 3D series.\n",
      "\n",
      "Title: The Humpbacked Horse (1941 film)\n",
      "Target Class: Film\n",
      "Content:\n",
      "  The Humpbacked Horse (Russian: Конёк-Горбунок) is a 1941 Soviet film directed by Alexander Rou and produced at Soyuzdetfilm studios. It is based on a fairy tale by Pyotr Pavlovich Yershov.\n",
      "\n",
      "Title: Child of the Prophecy\n",
      "Target Class: WrittenWork\n",
      "Content:\n",
      "  Child of the Prophecy is an historical fantasy novel by Juliet Marillier and the third book in the Sevenwaters Trilogy first published in 2001. Book Three steps slightly out of the tradition of Sevenwaters with the young heroine Fainne being raised far from the homestead in Kerry. Fainne is the daughter of Niamh and Ciaran and is a dangerous combination of four races.\n",
      "\n",
      "Title: Harold Hess Lustron House\n",
      "Target Class: Building\n",
      "Content:\n",
      "  Harold Hess Lustron House is located in Closter Bergen County New Jersey United States. The house was built in 1950 and was added to the National Register of Historic Places on July 25 2000.\n",
      "\n",
      "Title: Jaquirana River\n",
      "Target Class: NaturalPlace\n",
      "Content:\n",
      "  Jaquirana River is a river of Amazonas state in north-western Brazil.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_dbpedia_data(data, classes, sample_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### Deep Convolutional Neural Network for text classification in TensorFlow-Slim\n",
    "-  Define Deep Convolutional Neural Network for classification task on text dataset.\n",
    "\n",
    "<img src=\"../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-latest]",
   "language": "python",
   "name": "conda-env-TF-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

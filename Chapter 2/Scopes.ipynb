{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Scopes` in TensorFlow-Slim\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../images/tensorflow.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scopes\n",
    "\n",
    "Native TensorFlow already provides scoping mechanisms that help organize and simplify your code with `name_scope` and `variable_scope`.\n",
    "\n",
    "TF-Slim provides a new scope called `arg_scope`. This scope lets you specify default arguments for specific operations within that scope. This becomes especially useful when dealing with very deep neural networks.\n",
    "\n",
    "## Deep CNNs\n",
    "<img src=\"../images/VGG.jpg\" width=\"800\">\n",
    "\n",
    "<img src=\"../images/inception.png\" width=\"1000\">\n",
    "\n",
    "**Other very deep neural network architectures**\n",
    "- [Residual Networks](https://arxiv.org/abs/1512.03385)\n",
    "- [Dense Networks](https://arxiv.org/abs/1608.06993)\n",
    "\n",
    "The following methods will be covered in this notebook:\n",
    "```\n",
    "slim.arg_scope\n",
    "slim.l2_regularizer\n",
    "slim.flatten\n",
    "slim.utils.convert_collection_to_dict\n",
    "slim.batch_norm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append(\"../\") \n",
    "\n",
    "from utils.pretty_printer import inspect_variables, inspect_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Scope\n",
    "\n",
    "    => slim.arg_scope(*args, **kwds)\n",
    "    Docstring:\n",
    "    Stores the default arguments for the given set of list_ops.\n",
    "\n",
    "    Args:\n",
    "      list_ops_or_scope: List or tuple of operations to set argument scope for or\n",
    "        a dictionary containing the current scope.\n",
    "      **kwargs: keyword=value that will define the defaults for each op in\n",
    "                list_ops. All the ops need to accept the given set of arguments.\n",
    "\n",
    "    Yields:\n",
    "      the current_scope, which is a dictionary of {op: {arg: value}}\n",
    "\n",
    "## Define Slim model\n",
    "Using argument scoping a 11-layer neural net can be made cleaner, simpler and easier to maintain. Argument values specified in the scope can be overridden in two ways:\n",
    "- locally - define the argument directly in the function call.\n",
    "- nested scopes - define mutiple `arg_scopes` within eachother.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def slim_model(inputs):\n",
    "\n",
    "    # defaut parameters for conv2d and fully_connected layers\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                          biases_initializer=tf.constant_initializer(1.0),\n",
    "                          weights_regularizer=slim.l2_regularizer(0.05)):\n",
    "        # baises_regularizer is left None\n",
    "        # It is less common/useful, assuming proper data preprocessing/mean subtraction\n",
    "\n",
    "        # default parameters for conv2d (overrides previous scope)\n",
    "        with slim.arg_scope([slim.conv2d],\n",
    "                            kernel_size = [3,3],\n",
    "                            padding='SAME',\n",
    "                            biases_initializer=tf.constant_initializer(0.0)):\n",
    "            # zero bias initialization is more common\n",
    "            # asymmetry breaking is provided by the random initialization of weights\n",
    "             \n",
    "            # default parameters for max_pool2d    \n",
    "            with slim.arg_scope([slim.max_pool2d],\n",
    "                                kernel_size = [2,2],\n",
    "                                padding = 'SAME'):\n",
    "                # conv1\n",
    "                net = slim.repeat(inputs, 2, slim.conv2d, 64, scope='conv1')\n",
    "                net = slim.max_pool2d(net, scope='pool1')\n",
    "                # conv2\n",
    "                net = slim.repeat(net, 2, slim.conv2d, 128, scope='conv2')\n",
    "                net = slim.max_pool2d(net, scope='pool2')\n",
    "                # reshape tensor to matrix\n",
    "                net = slim.flatten(net)\n",
    "                # fc3\n",
    "                net = slim.fully_connected(net, 1024, scope='fc3')\n",
    "                net = slim.dropout(net, 0.5, scope='dropout3')\n",
    "                # fc4\n",
    "                net = slim.fully_connected(net, 256, scope='fc4')\n",
    "                net = slim.dropout(net, 0.5, scope='dropout4')\n",
    "                # linear prediction, override the activation_fn in scope\n",
    "                net = slim.fully_connected(net, 10, activation_fn=None, scope='linear')\n",
    "                # softmax4\n",
    "                # categorical probability distribution over output vector\n",
    "                outputs = slim.softmax(net, scope='softmax4')\n",
    "                return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add model to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    # 4D Tensor placeholder for input images\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, 32, 32, 3], name=\"images\")\n",
    "    \n",
    "    with tf.variable_scope(\"TF-Slim\", [inputs]):\n",
    "        # add model to graph\n",
    "        outputs = slim_model(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "name = TF-Slim/conv1/conv1_1/weights:0                         shape = (3, 3, 3, 64)\n",
      "name = TF-Slim/conv1/conv1_1/biases:0                          shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_2/weights:0                         shape = (3, 3, 64, 64)\n",
      "name = TF-Slim/conv1/conv1_2/biases:0                          shape = (64,)\n",
      "name = TF-Slim/conv2/conv2_1/weights:0                         shape = (3, 3, 64, 128)\n",
      "name = TF-Slim/conv2/conv2_1/biases:0                          shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_2/weights:0                         shape = (3, 3, 128, 128)\n",
      "name = TF-Slim/conv2/conv2_2/biases:0                          shape = (128,)\n",
      "name = TF-Slim/fc3/weights:0                                   shape = (8192, 1024)\n",
      "name = TF-Slim/fc3/biases:0                                    shape = (1024,)\n",
      "name = TF-Slim/fc4/weights:0                                   shape = (1024, 256)\n",
      "name = TF-Slim/fc4/biases:0                                    shape = (256,)\n",
      "name = TF-Slim/linear/weights:0                                shape = (256, 10)\n",
      "name = TF-Slim/linear/biases:0                                 shape = (10,)\n",
      "\n",
      "Inputs/Outputs:\n",
      "name = images:0                                                shape = (?, 32, 32, 3)\n",
      "name = TF-Slim/softmax4/Reshape_1:0                            shape = (?, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    print(\"Parameters:\")\n",
    "    inspect_variables(slim.get_variables(scope=\"TF-Slim\"))\n",
    "    print(\"Inputs/Outputs:\")\n",
    "    inspect_variables([inputs, outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Layer Structure\n",
    "As neural networks gets deeper and more complicated it is important to keep track of the shape of your data as it passes through every layer operations in the graph. Argument scoping and other slim functions can help us keep track of the layer transformations.\n",
    "\n",
    "---\n",
    "    => slim.utils.convert_collection_to_dict(collection)\n",
    "    Docstring:\n",
    "    Returns an OrderedDict of Tensors using get_tensor_alias as key.\n",
    "\n",
    "    Args:\n",
    "      collection: A collection.\n",
    "\n",
    "    Returns:\n",
    "      An OrderedDict of {get_tensor_alias(tensor): tensor}\n",
    "      \n",
    "## Argument Scoping for Collecting Layer Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, 32, 32, 3], name=\"images\")\n",
    "    \n",
    "    with tf.variable_scope('TF-Slim', [inputs]) as vs:\n",
    "            end_points_collection = vs.original_name_scope + '_end_points'\n",
    "            \n",
    "            # Collect outputs/endpoints for conv2d, fully_connected and max_pool2d.\n",
    "            with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                                outputs_collections=end_points_collection):\n",
    "                # add model to graph\n",
    "                outputs = slim_model(inputs)\n",
    "                \n",
    "                # get the layer endpoints\n",
    "                end_points = slim.utils.convert_collection_to_dict(end_points_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Parameters and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "name = TF-Slim/conv1/conv1_1/weights:0                         shape = (3, 3, 3, 64)\n",
      "name = TF-Slim/conv1/conv1_1/biases:0                          shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_2/weights:0                         shape = (3, 3, 64, 64)\n",
      "name = TF-Slim/conv1/conv1_2/biases:0                          shape = (64,)\n",
      "name = TF-Slim/conv2/conv2_1/weights:0                         shape = (3, 3, 64, 128)\n",
      "name = TF-Slim/conv2/conv2_1/biases:0                          shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_2/weights:0                         shape = (3, 3, 128, 128)\n",
      "name = TF-Slim/conv2/conv2_2/biases:0                          shape = (128,)\n",
      "name = TF-Slim/fc3/weights:0                                   shape = (8192, 1024)\n",
      "name = TF-Slim/fc3/biases:0                                    shape = (1024,)\n",
      "name = TF-Slim/fc4/weights:0                                   shape = (1024, 256)\n",
      "name = TF-Slim/fc4/biases:0                                    shape = (256,)\n",
      "name = TF-Slim/linear/weights:0                                shape = (256, 10)\n",
      "name = TF-Slim/linear/biases:0                                 shape = (10,)\n",
      "\n",
      "Layers:\n",
      "name = TF-Slim/conv1/conv1_1/Relu:0                            shape = (?, 32, 32, 64)\n",
      "name = TF-Slim/conv1/conv1_2/Relu:0                            shape = (?, 32, 32, 64)\n",
      "name = TF-Slim/pool1/MaxPool:0                                 shape = (?, 16, 16, 64)\n",
      "name = TF-Slim/conv2/conv2_1/Relu:0                            shape = (?, 16, 16, 128)\n",
      "name = TF-Slim/conv2/conv2_2/Relu:0                            shape = (?, 16, 16, 128)\n",
      "name = TF-Slim/pool2/MaxPool:0                                 shape = (?, 8, 8, 128)\n",
      "name = TF-Slim/fc3/Relu:0                                      shape = (?, 1024)\n",
      "name = TF-Slim/fc4/Relu:0                                      shape = (?, 256)\n",
      "name = TF-Slim/linear/BiasAdd:0                                shape = (?, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    print(\"Parameters:\")\n",
    "    inspect_variables(slim.get_variables(scope=\"TF-Slim\"))\n",
    "    print(\"Layers:\")\n",
    "    inspect_layers(end_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Batch Normalization\n",
    "\n",
    "**Problem with training deeper neural networks**\n",
    "- *Internal Covariate Shift*\n",
    "    - change in the input distribution to internal layers of deep networks.\n",
    "    - the covariate shift is amplified down the network.\n",
    "- *Vanishing Gradient*\n",
    "    - nonlinearities like tanh or sigmoid tend to get stuck in the saturation region as the network grows deeper.\n",
    "    - instead use ReLU (no saturation region), smaller learning rates, careful initializations.\n",
    "    \n",
    "** Whats is Batch Normalization?**\n",
    "\n",
    "The Batch Normalization is wildly popular a method that addresses the various issues related to training of Deep Neural Networks. It has led to significant performance improvements in state-of-the-art models, by making normalization a part of the neural network architecture itself. \n",
    "\n",
    "<br>\n",
    "<div style=\"float:left;margin-right:5px;\">\n",
    "    <img src=\"../images/BN3.png\" width=\"400\" />\n",
    "    <p style=\"text-align:center;\">*Batch Normalization Implementation*</p>\n",
    "</div>\n",
    "<div style=\"float:center;margin-right:5px;\">\n",
    "    <img src=\"../images/BN1.png\" width=\"400\" />\n",
    "    <p style=\"text-align:center;\">* Validation accuracy of Inception\n",
    "and its batch-normalized variants vs. number of\n",
    "training steps*</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "** Advantages of Batch Normalization**\n",
    "- Faster convergence with higher learning rate.\n",
    "- More stable input distrubtion (reduction of covariate shift).\n",
    "- Training gradients are less sensitive to input/parameter scale and initialization.\n",
    "- Regularizes the model and reduces the need for dropout, l2/l1 regularization.\n",
    "- Model trains with saturating nonlinearities (avoids vanishing gradients)\n",
    "\n",
    "<img src=\"../images/BN2.png\" width=\"800\" align=center>\n",
    "<center>* (a) The test accuracy of the MNIST network\n",
    "trained with and without Batch Normalization, vs. the\n",
    "number of training steps. Batch Normalization helps the\n",
    "network train faster and achieve higher accuracy. (b,\n",
    "c) The evolution of input distributions to a typical sigmoid,\n",
    "over the course of training, shown as {15, 50, 85}th\n",
    "percentiles. *</center>\n",
    "\n",
    "** Want to learn more?**\n",
    "- [Batch Normalization: Accelerating Deep Network Training b\n",
    "y\n",
    "Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167v3.pdf) (the original paper)\n",
    "- [Batch Normalization in\n",
    "Neural Network](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&cad=rja&uact=8&ved=0ahUKEwj5s430ge3QAhUP3mMKHaFaCdkQFghOMAc&url=https%3A%2F%2Fbcourses.berkeley.edu%2Ffiles%2F66022277%2Fdownload%3Fdownload_frd%3D1%26verifier%3DoaU8pqXDDwZ1zidoDBTgLzR8CPSkWe6MCBKUYan7&usg=AFQjCNGHyy4qhRcwLLU2RunAgM3iqFMcjQ&sig2=topE-0sw8Qb08mPfdBXO4A&bvm=bv.141320020,d.cGw)\n",
    "- [Understanding the backward pass through Batch Normalization Layer](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Slim Model with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slim_model_BN(inputs):\n",
    "\n",
    "    # defaut parameters for conv2d and fully_connected layers\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                          biases_initializer=tf.constant_initializer(1.0),\n",
    "                          weights_regularizer=slim.l2_regularizer(0.05)):\n",
    "\n",
    "        # default parameters for conv2d (overrides previous scope)\n",
    "        with slim.arg_scope([slim.conv2d],\n",
    "                            kernel_size = [3,3],\n",
    "                            padding='SAME',\n",
    "                            normalizer_fn=slim.batch_norm, # add batch normalization layer\n",
    "                            biases_initializer=tf.constant_initializer(0.0)):\n",
    "             \n",
    "            # default parameters for max_pool2d    \n",
    "            with slim.arg_scope([slim.max_pool2d],\n",
    "                                kernel_size = [2,2],\n",
    "                                padding = 'SAME'):\n",
    "                # conv1\n",
    "                net = slim.repeat(inputs, 2, slim.conv2d, 64, scope='conv1')\n",
    "                net = slim.max_pool2d(net, scope='pool1')\n",
    "                # conv2\n",
    "                net = slim.repeat(net, 2, slim.conv2d, 128, scope='conv2')\n",
    "                net = slim.max_pool2d(net, scope='pool2')\n",
    "                # reshape tensor to matrix\n",
    "                net = slim.flatten(net)\n",
    "                # fc3\n",
    "                net = slim.fully_connected(net, 1024, scope='fc3')\n",
    "                net = slim.dropout(net, 0.5, scope='dropout3')\n",
    "                # fc4\n",
    "                net = slim.fully_connected(net, 256, scope='fc4')\n",
    "                net = slim.dropout(net, 0.5, scope='dropout4')\n",
    "                # linear prediction, override the activation_fn in scope\n",
    "                net = slim.fully_connected(net, 10, activation_fn=None, scope='linear')\n",
    "                # softmax4\n",
    "                outputs = slim.softmax(net, scope='softmax4')\n",
    "                return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, 32, 32, 3], name=\"images\")\n",
    "    \n",
    "    with tf.variable_scope('TF-Slim', [inputs]) as vs:\n",
    "            end_points_collection = vs.original_name_scope + '_end_points'\n",
    "            \n",
    "            # Collect outputs/endpoints for conv2d, fully_connected and max_pool2d.\n",
    "            with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                                outputs_collections=end_points_collection):\n",
    "                # add model to graph\n",
    "                outputs = slim_model_BN(inputs)\n",
    "                \n",
    "                # get the layer endpoints\n",
    "                end_points = slim.utils.convert_collection_to_dict(end_points_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Parameters and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "name = TF-Slim/conv1/conv1_1/weights:0                         shape = (3, 3, 3, 64)\n",
      "name = TF-Slim/conv1/conv1_1/BatchNorm/beta:0                  shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_1/BatchNorm/moving_mean:0           shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_1/BatchNorm/moving_variance:0       shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_2/weights:0                         shape = (3, 3, 64, 64)\n",
      "name = TF-Slim/conv1/conv1_2/BatchNorm/beta:0                  shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_2/BatchNorm/moving_mean:0           shape = (64,)\n",
      "name = TF-Slim/conv1/conv1_2/BatchNorm/moving_variance:0       shape = (64,)\n",
      "name = TF-Slim/conv2/conv2_1/weights:0                         shape = (3, 3, 64, 128)\n",
      "name = TF-Slim/conv2/conv2_1/BatchNorm/beta:0                  shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_1/BatchNorm/moving_mean:0           shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_1/BatchNorm/moving_variance:0       shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_2/weights:0                         shape = (3, 3, 128, 128)\n",
      "name = TF-Slim/conv2/conv2_2/BatchNorm/beta:0                  shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_2/BatchNorm/moving_mean:0           shape = (128,)\n",
      "name = TF-Slim/conv2/conv2_2/BatchNorm/moving_variance:0       shape = (128,)\n",
      "name = TF-Slim/fc3/weights:0                                   shape = (8192, 1024)\n",
      "name = TF-Slim/fc3/biases:0                                    shape = (1024,)\n",
      "name = TF-Slim/fc4/weights:0                                   shape = (1024, 256)\n",
      "name = TF-Slim/fc4/biases:0                                    shape = (256,)\n",
      "name = TF-Slim/linear/weights:0                                shape = (256, 10)\n",
      "name = TF-Slim/linear/biases:0                                 shape = (10,)\n",
      "\n",
      "Layers:\n",
      "name = TF-Slim/conv1/conv1_1/Relu:0                            shape = (?, 32, 32, 64)\n",
      "name = TF-Slim/conv1/conv1_2/Relu:0                            shape = (?, 32, 32, 64)\n",
      "name = TF-Slim/pool1/MaxPool:0                                 shape = (?, 16, 16, 64)\n",
      "name = TF-Slim/conv2/conv2_1/Relu:0                            shape = (?, 16, 16, 128)\n",
      "name = TF-Slim/conv2/conv2_2/Relu:0                            shape = (?, 16, 16, 128)\n",
      "name = TF-Slim/pool2/MaxPool:0                                 shape = (?, 8, 8, 128)\n",
      "name = TF-Slim/fc3/Relu:0                                      shape = (?, 1024)\n",
      "name = TF-Slim/fc4/Relu:0                                      shape = (?, 256)\n",
      "name = TF-Slim/linear/BiasAdd:0                                shape = (?, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    print(\"Parameters:\")\n",
    "    inspect_variables(slim.get_variables(scope=\"TF-Slim\"))\n",
    "    print(\"Layers:\")\n",
    "    inspect_layers(end_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### Multi-layer Feedforward Neural Network in TensorFlow-Slim\n",
    "-  Define feedforward network for classification task on synthetic dataset.\n",
    "\n",
    "<img src=\"../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF-latest]",
   "language": "python",
   "name": "conda-env-TF-latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
